{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN trained on the MNIST dataset for image classification \n",
    "\n",
    "In this notebook we are going to get familiar with using PyTorch, a deep learning library, to train a simple neural network. The network will be trained on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) which contains small images of handwritten numerical digits. By the end of this training, the model should be able to accurately classify images with numerical digits.\n",
    "\n",
    "Training a network on the MNIST dataset has become the 'hello world' of machine learning. \n",
    "\n",
    "Once you run this code, you can compare it with the code in the notebook `02`. \n",
    "\n",
    "First let's do some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PILLOW_VERSION' from 'PIL' (c:\\Users\\admin\\miniconda3\\envs\\DMLAP\\lib\\site-packages\\PIL\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\miniconda3\\envs\\DMLAP\\lib\\site-packages\\torchvision\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[1;32mc:\\Users\\admin\\miniconda3\\envs\\DMLAP\\lib\\site-packages\\torchvision\\datasets\\__init__.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvhn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVHN\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mphototour\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PhotoTour\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfakedata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeData\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msemeion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SEMEION\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01momniglot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Omniglot\n",
      "File \u001b[1;32mc:\\Users\\admin\\miniconda3\\envs\\DMLAP\\lib\\site-packages\\torchvision\\datasets\\fakedata.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFakeData\u001b[39;00m(data\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A fake dataset that returns randomly generated images and returns them as PIL images\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\miniconda3\\envs\\DMLAP\\lib\\site-packages\\torchvision\\transforms\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\admin\\miniconda3\\envs\\DMLAP\\lib\\site-packages\\torchvision\\transforms\\transforms.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     20\u001b[0m     Sequence \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mSequence\n",
      "File \u001b[1;32mc:\\Users\\admin\\miniconda3\\envs\\DMLAP\\lib\\site-packages\\torchvision\\transforms\\functional.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps, ImageEnhance, PILLOW_VERSION\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maccimage\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PILLOW_VERSION' from 'PIL' (c:\\Users\\admin\\miniconda3\\envs\\DMLAP\\lib\\site-packages\\PIL\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define our hyperparameters\n",
    "\n",
    "Now let's define our hyperparameters. Add a comment for each variable. What are these variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "device = 'cpu'\n",
    "#\n",
    "num_epochs = 10\n",
    "#\n",
    "num_classes = 10\n",
    "#\n",
    "batch_size = 100\n",
    "#\n",
    "learn_rate = 0.001\n",
    "#\n",
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image transformations\n",
    "\n",
    "torchvision.transforms.ToTensor converts a python image (PIL) or numpy.ndarray to tensor.\n",
    "\n",
    "torchvision.transforms.Normalize(mean, std, inplace=False) normalizes a tensor image with mean and standard deviation.\n",
    "\n",
    "Look in [here](https://pytorch.org/vision/0.9/transforms.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create our train and test datasets\n",
    "\n",
    "Torchvision provides many built-in datasets in the torchvision.datasets module. MNIST is one of them. You can find more [here](https://pytorch.org/vision/stable/datasets.html).\n",
    "\n",
    "MNIST is composed of a train set (60,000 images) and a test set (10,000 images). Only the train set will be used for the training. The test set is meant to be used after the training is completed, to see how the model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root=data_path, train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root=data_path, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are these tensors? What is the difference between `data` and `targets`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(mnist_trainset.data.shape, mnist_trainset.targets.shape)\n",
    "#\n",
    "print(mnist_testset.data.shape, mnist_testset.targets.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualise a sample image along with its respective label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 1000 # change this number to have a glimpse into another item of the trainset\n",
    "\n",
    "# using numpy\n",
    "# turn the tensor into a numpy array\n",
    "sample_np = mnist_trainset.data[img_num].numpy() \n",
    "# add a wide linewidth to prevent wrapping\n",
    "np.set_printoptions(linewidth=150) \n",
    "print(f\"Label: {mnist_trainset.targets[img_num]}\")\n",
    "print()\n",
    "print(sample_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using matplotlib\n",
    "# plotting for one image\n",
    "plt.figure()\n",
    "plt.title(f\"Label: {mnist_trainset.targets[img_num]}\")\n",
    "plt.imshow(mnist_trainset.data[img_num], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for multiple images, randomly selected\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    # generate a random index between 0 and len(mnist_trainset)-1, inclusive\n",
    "    sample_idx = torch.randint(len(mnist_trainset), size=(1,)).item()\n",
    "    # retrieve the image and the respective label for that index\n",
    "    img, label = mnist_trainset[sample_idx]\n",
    "    # create the grid of subplots within the bigger plot\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    # squeeze() removes all dimensions with size 1\n",
    "    # try running the cell without squeezing the image and observe the returned error \n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create our train and test dataloaders\n",
    "\n",
    "A DataLoader wraps an iterable around the Dataset, allowing us to iterate over batches of data when training. The DataLoader can shuffle the data at the beginning of each epoch if the shuffle parameter is set to True. Shuffling helps in randomizing the order of data samples and prevents the model from learning any order-specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define our simple fully connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        #\n",
    "        super(ClassificationNetwork,self).__init__()\n",
    "        #\n",
    "        self.fc1 = nn.Linear(28*28, 128) \n",
    "        #\n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        #\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #\n",
    "        x = torch.flatten(x, 1)\n",
    "        #\n",
    "        x = self.fc1(x)\n",
    "        #\n",
    "        x = F.relu(x)\n",
    "        #\n",
    "        x = self.fc2(x)\n",
    "        #\n",
    "        x = F.relu(x)\n",
    "        #\n",
    "        x = self.fc3(x)\n",
    "        #\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup core training objects\n",
    "\n",
    "Look into available loss functions [here](https://pytorch.org/docs/stable/nn.html#loss-functions).\n",
    "\n",
    "Look into available optimizers [here](https://pytorch.org/docs/stable/optim.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationNetwork()\n",
    "model.to(device)\n",
    "\n",
    "# selecting cross entropy as the loss function for our classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# selecting Adam as our optimization algorithm based on which the parameters, i.e. weight, will be updated\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "# print model architecture\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # training loop\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # get data\n",
    "        inputs = data.to(device)\n",
    "        labels = target.to(device)\n",
    "        \n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        predictions = model(inputs)\n",
    "        # compute the loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # update the parameters, i.e. weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # save statistics to plot later\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # normalise cumulative losses to dataset size\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    # added cumulative losses to list to plot later\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, train loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot loss values as stored during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Train loss\")\n",
    "plt.plot(train_losses,label=\"train\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cumulative loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test model on the MNIST test dataset\n",
    "\n",
    "A process also known as Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# disabling gradient computation since there is no need to update any parameters\n",
    "with torch.no_grad():\n",
    "    # iterate over batches in the test_loader\n",
    "    for data, target in test_loader:\n",
    "        # forward pass\n",
    "        predictions = model(data)\n",
    "        # get the index of the maximum predicted value (predicted class)\n",
    "        # the underscore is a variable to be ignored - a placeholder for the maximum values\n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        # update the total number of samples by adding the current batch\n",
    "        total += target.size(0)\n",
    "        # update the count of correct predictions by summing the correct predictions in the current batch\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy}\\n Number of Correct Predictions: {correct} out of {total}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualise some predictions based on the MNIST test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disabling gradient computation since there is no need to update any parameters\n",
    "with torch.no_grad():\n",
    "    num_images = 5\n",
    "    figure = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    for i in range(1, num_images + 1):\n",
    "        sample_idx = torch.randint(len(mnist_testset), size=(1,)).item()\n",
    "        img, label = mnist_testset[sample_idx]\n",
    "        output = model(img)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        figure.add_subplot(1, num_images, i)\n",
    "        plt.title(f\"Predicted: {predicted.item()}\\nActual: {label}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualise some predictions based on external inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = './data/sample-numbers/seven-rgb.jpg'\n",
    "\n",
    "# function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # convert the image to black and white and transform it to match the required input format for the model\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    img_tensor = transform(img)\n",
    "    # img is an array for the plot and img_tensor is a tensor to pass through the model\n",
    "    return img, img_tensor\n",
    "\n",
    "# preprocess the image\n",
    "image, tensor_image = preprocess_image(img_path)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # forward pass\n",
    "    prediction = model(tensor_image)\n",
    "    # get the predicted class\n",
    "    _, predicted_class = torch.max(prediction, 1)\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f'Predicted Class: {predicted_class.item()}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/mnist_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks to do in-class and further explore at home\n",
    "\n",
    "**Task 1:** Run all the cells in this code to train a simple NN on the MNIST dataset.\n",
    "\n",
    "**Task 2:** Go through the notebook, cell by cell, and try to understand what each cell does, even if you do not understand each one of the commands seperately. The important thing is to roughly understand the whole process of the training. Training a NN in PyTorch is a great opportunity to see all the theory of training in practice.\n",
    "\n",
    "**Task 3:** Go through the notebook once again and add comments wherever you see a `#`. Consult [the pytorch documentation page](https://pytorch.org/docs/stable/index.html) for anything you are unsure about. \n",
    "\n",
    "**Task 4:** Add other images of handwritten digits in the data folder and test your model on those within the cell `Visualise some predictions based on external inputs`. You can add images you download from the internet, or you could get more experimental and e.g. create handwritten digits on paper and load them here, or create b-w digits in p5 or other environments and test how the model performs on all of these cases. Test the model's limits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

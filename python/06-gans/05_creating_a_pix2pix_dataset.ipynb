{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating your own pix2pix dataset\n",
        "=================================\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation requirements\n",
        "\n",
        "To run this notebook you might need to install some new Python packages. To do so, open a terminal and first make sure your environment is active\n",
        "```\n",
        "conda activate dmlap\n",
        "```\n",
        "and then\n",
        "```\n",
        "conda install -c conda-forge pycairo opencv scikit-image \n",
        "conda install -c conda-forge face_recognition\n",
        "pip install pyglet\n",
        "```\n",
        "\n",
        "If you have not done so already, you should also need to install the [py5canvas](https://github.com/colormotor/py5canvas) module. To do so use \n",
        "```\n",
        "pip install git+https://github.com/colormotor/py5canvas.git\n",
        "```\n",
        "\n",
        "### Updating py5canvas\n",
        "If you already installed py5canvas, you will need to updated it to the latest version. To do so use \n",
        "```\n",
        "pip install --upgrade  --force-reinstall --no-deps git+https://github.com/colormotor/py5canvas.git\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Modules\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage import io, transform\n",
        "import cv2\n",
        "import glob\n",
        "from tqdm.auto import tqdm\n",
        "import random"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up \n",
        "Set your directories and the dataset specifics\n",
        "\n",
        "-   `target_path` defines where your **target** images are located.\n",
        "-   `source_path` defines where your **source** images are located, if you already have these. Otherwise, set this to an empty string `''`.\n",
        "-   `dataset_path` defines where your pix2pix dataset will be saved.\n",
        "-   `is_input_pix_to_pix` set this to `True` if the input dataset already consists of an source and target pairs. This will be the case if you want to modify an existing pix2pix dataset. In this case we need to extract only the target.\n",
        "-   `input_target_index` if we are manipulating a dataset that is already a pix2pix dataset, this defines whether the target image is to the left (`0`) or to the right (`1`).\n",
        "\n",
        "Note you will have to put exactly the path to your image directories here, this code does not recursively search for images. Also note that the most common use case for this system will be with you providing an dataset of targets (desired outputs) that you will process to create the corresponding inputs (e.g. with edge detection or finding face landmarks). In that case you should not worry about the `source_path` directory below.\n",
        "\n",
        "Here, by default we will load the &ldquo;Face 2 comics&rdquo; dataset. Download the dataset from [https://www.kaggle.com/datasets/defileroff/comic-faces-paired-synthetic](https://www.kaggle.com/datasets/defileroff/comic-faces-paired-synthetic), unzip, and place the `face2comics_v1.0.0_by_Sxela` direcory in your dataset directory. This is already a &ldquo;pix2pix-friendly&rdquo; dataset consisting, however, of pairs of images that are separated. We will use the images to create an &ldquo;Edges to comics&rdquo; dataset, where we apply edge detection to a subset of the source images and leave the corresponding comic version unchanged.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "target_path = './datasets/face2comics_v1.0.0_by_Sxela/comics/'\n",
        "source_path = './datasets/face2comics_v1.0.0_by_Sxela/face/'  # Only used if we already have source image examples\n",
        "dataset_path = './datasets/edge2comics'\n",
        "max_images = 500\n",
        "is_input_pix_to_pix = False\n",
        "input_target_index = 1\n",
        "\n",
        "# Uncomment and adjust paths to perform face detection as the source\n",
        "# target_path = './datasets/edges2rembrandt'\n",
        "# source_path = ''\n",
        "# dataset_path = './datasets/landmarks2rembrandt'\n",
        "# max_images = 500\n",
        "# is_input_pix_to_pix = True\n",
        "# input_target_index = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code above also contains a commented section with paths for the case in which you already have a pix2pix dataset with 512x256 images, and you want to replace the input with a custom one. Later in the code there is a commented section that will identify face landmarks in the targets of the dataset (the right image) and use these as an input. For this specific example to work, it is expected that you download the [\"rembrandt pix2pix dataset\"](https://www.kaggle.com/datasets/grafstor/rembrandt-pix2pix-dataset/code) and unzip the images into a \"edges2rembrandt\" folder inside the dataset folder relative to this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the images to process\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let&rsquo;s load our target images, and optionally our source images if we have set the `source_path` directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def load_image(path):\n",
        "    w, h = (256, 256)\n",
        "    if is_input_pix_to_pix: # In case we are already loading a pix2pix image\n",
        "        w, h = (512, 256)\n",
        "    img = io.imread(path) #image.load_img(path, target_size=size)\n",
        "    img = transform.resize(img, (h, w), anti_aliasing=True)\n",
        "    # If we are loading a pix2pix dataset just extract the target\n",
        "    if is_input_pix_to_pix:\n",
        "        if input_target_index==0:\n",
        "            img = img[:,:h,:]\n",
        "        else:\n",
        "            img = img[:,h:,:]\n",
        "    return (img*255).astype(np.uint8)\n",
        "\n",
        "def load_images_in_path(path):\n",
        "    files = glob.glob(path + '/*')\n",
        "    images = []\n",
        "    if max_images:\n",
        "        n = len(files)\n",
        "        files = files[:max_images]\n",
        "        print('%d of %d images'%(len(files), n))\n",
        "    else:\n",
        "        print('%d images'%len(files))\n",
        "    for imgfile in tqdm(files): #, desc='Loading images in ' + path):\n",
        "        img = load_image(imgfile)\n",
        "        images.append(img)\n",
        "    return images\n",
        "\n",
        "print('Loading targets')\n",
        "target_images = load_images_in_path(target_path)\n",
        "if source_path:\n",
        "    print('Loaded sources')\n",
        "    source_images = load_images_in_path(source_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_images[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define our transformation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code below has a number of transformations already setup for you. These are:\n",
        "\n",
        "-   `apply_canny_cv2` Applys Canny edge detection by using OpenCV. You can set two parameters (thresholds between 0 and 255) that will determine the result of the edge detection: `thresh1` and `thresh2`. Experiment with these values to adjust the results to your liking. Additional details can be seen [here](https://docs.opencv.org/4.x/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de).\n",
        "-   `apply_canny_skimage` Applys Canny edge detection by using [scikit-image](https://scikit-image.org). You can set one parameter, `sigma` that determines the number of edges. In general, a higher number will produce less edges. See [this](https://scikit-image.org/docs/stable/auto_examples/edges/plot_canny.html) for additional details.\n",
        "-   `apply_face_landmarks` Finds face landmarks in an image by using [face_recognition](https://pypi.org/project/face-recognition/) and uses the Canvas API to draw these as polygons. Note that this function will fail if the face detector cannot find a face in the image. The code is set up so the image won't be included in the generated dataset if face detection fails.\n",
        "-   `load_source` assumes the `source_path` directory has been set, and simply loads an image from the directory leaving it unchanged. Use this if you wish to convert a dataset made of separate images, into a dataset consisting of 512X256 sized images (the format expected by the model provided in class). \n",
        "-   `transformation(transformation type)` takes an image from the directory specified in `source_path`. Note that this is a function call (it returns a function). You can optionally set an additional transformation to the image by setting the `transform_func` parameter to one of the functions above. For example setting `transform=apply_canny_skimage` will apply the Canny edge detection algorithm to the loaded source image. By default, no transormation is applied.\n",
        "\n",
        "Set the `image_transformation` in the code below to the function that describes the transformation you want to apply.\n",
        "If you feel confident, you can extend this to other image transformations by duplicating one of the functions and adapting it to your needs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skimage import feature, filters\n",
        "\n",
        "def apply_canny_cv2(index, img, thresh1=160, thresh2=250):\n",
        "    import cv2\n",
        "    invert = False\n",
        "    grayimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    edges = cv2.Canny(grayimg, thresh1, thresh2)\n",
        "    if invert:\n",
        "        edges = cv2.bitwise_not(edges)\n",
        "    return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "def apply_canny_skimage(index, img, sigma=1.5):\n",
        "    import cv2\n",
        "    from skimage import feature\n",
        "    invert = False\n",
        "    grayimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    edges = (feature.canny(grayimg, sigma=sigma)*255).astype(np.uint8)\n",
        "    if invert:\n",
        "        edges = cv2.bitwise_not(edges)\n",
        "    return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "def apply_face_landmarks(index, img, stroke_weight=2):\n",
        "    from py5canvas import canvas\n",
        "    import face_recognition\n",
        "    \n",
        "    c = canvas.Canvas(256, 256)\n",
        "    c.background(0)\n",
        "    landmarks = face_recognition.face_landmarks(img)\n",
        "\n",
        "    if not landmarks:\n",
        "        print('Failed to find landmarks')\n",
        "        return None\n",
        "    c.stroke_weight(stroke_weight)\n",
        "    c.no_fill()\n",
        "    c.stroke(255)\n",
        "    for points in landmarks[0].values():\n",
        "        c.polyline(points)\n",
        "    return c.get_image()\n",
        "\n",
        "def load_source(index, img):\n",
        "    if not source_path:\n",
        "        raise ValueError(\"Source path must be specified\")\n",
        "    return source_images[index]\n",
        "\n",
        "def do_nothing(index, img):\n",
        "    return img\n",
        "\n",
        "# As it is, this version loads an image from the source_image directory and applies the Canny edge detection\n",
        "# algorithm to it. Set transform=None if you just want to load that image without processing\n",
        "def transformed_source(transform):\n",
        "    if not source_path:\n",
        "        raise ValueError(\"Source path must be specified\")\n",
        "    def func(index, img):\n",
        "        return transform(index, source_images[index])\n",
        "    return func\n",
        "\n",
        "# This takes an image in the `source_path`` directory and applys edge detection to it,\n",
        "# creating a new source\n",
        "#source_func = transformed_source(apply_canny_skimage)\n",
        "\n",
        "# This applies edge detection to the target image, making it the source to the tranformation you want to apply. If you are only working with a single folder of images that you\n",
        "# image_tranformation = apply_canny_skimage\n",
        "\n",
        "# This tries to find face landmarks in the target and creates a new source\n",
        "source_func = apply_face_landmarks # <- Use this for face detection\n",
        "\n",
        "# By default, just pass through the target image with no transformation\n",
        "target_func = do_nothing\n",
        "\n",
        "# Show an example\n",
        "i = 1\n",
        "img = target_images[i]\n",
        "src = source_func(i, img)\n",
        "plt.figure()\n",
        "plt.subplot(1, 2, 1)\n",
        "if src is not None:\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the dataset!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we loop through all the target images, generate the source image and stitch these together into a single image. The input image directory might contain more than the desired number of images. If we want to process a lower number, set the `num_images` variable to a non-zero value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# target_index = 1 # You can redefine this if you wish for example to flip target and source\n",
        "\n",
        "num_images = 500\n",
        "shuffle = True\n",
        "image_indices = list(range(len(target_images)))\n",
        "if shuffle:\n",
        "    random.shuffle(image_indices)\n",
        "if num_images != 0:\n",
        "    image_indices = image_indices[:num_images]\n",
        "\n",
        "os.makedirs(dataset_path, exist_ok=True)\n",
        "\n",
        "index = 1\n",
        "for i in tqdm(image_indices, desc='Saving dataset to ' + dataset_path):\n",
        "    target = target_func(i, target_images[i])\n",
        "    source = source_func(i, target) \n",
        "    if source is None:\n",
        "        print('Failed to transform image %d of %d'%(i+1, len(image_indices)))\n",
        "        continue\n",
        "\n",
        "    if target_index==1:\n",
        "        combined = np.hstack([source, target])\n",
        "    else:\n",
        "        combined = np.hstack([target, source])\n",
        "    io.imsave(os.path.join(dataset_path, '%d.png'%(index)), combined)\n",
        "    index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "org": null,
    "vscode": {
      "interpreter": {
        "hash": "1c544d3133b9d8c6f36fca025551af31afa9ef134259e7064ad6be0c15e6401c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
